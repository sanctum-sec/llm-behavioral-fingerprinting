# Reading Room

A curated collection of research papers related to LLM behavioral analysis, censorship, security, and geopolitical bias.

---

## Censorship Bias

| Paper | Authors | Venue | Summary |
|-------|---------|-------|---------|
| [An Analysis of Chinese Censorship Bias in LLMs](censorship-bias/popets-2025-0122.pdf) | Mohamed Ahmed (Citizen Lab), Jeffrey Knockel (Citizen Lab/Bowdoin College), Rachel Greenstadt (NYU) | POPETS 2025(4) | Investigates how training on censored Chinese internet content creates measurable censorship bias in LLMs. Introduces CensorshipDetector, a 91%-accurate classifier for detecting sanitized responses. Key finding: Simplified Chinese prompts receive more censored responses than Traditional Chinese, suggesting mainland training data contamination. |

---

## LLM Security

*Papers on LLM vulnerabilities, prompt injection, and security properties.*

(No papers yet)

---

## Adversarial Attacks

*Papers on jailbreaking, red-teaming, and adversarial prompting.*

(No papers yet)

---

## Guardrails & Alignment

*Papers on safety mechanisms, RLHF, and alignment techniques.*

(No papers yet)

---

## Geopolitical AI

*Papers on national AI strategies, model provenance, and geopolitical implications.*

(No papers yet)

---

## Contributing

When adding papers:
1. Place the PDF in the appropriate category folder
2. Add an entry to the table above with authors, venue, and a 2-3 sentence summary
3. If a paper spans categories, list it in the most relevant one with cross-references
